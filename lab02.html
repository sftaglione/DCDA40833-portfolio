<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Lab 02 – AI Tool Evaluation</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>

<header>

    <!-- Navigation -->
    <nav>
  <ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="lab02.html">Lab 02: AI Evaluation</a></li>
    <li><a href="lab03.html">Lab 03: Visualization Critique</a></li>
  </ul>
</nav>

    <h1>Lab 02: AI Experimentation & Evaluation</h1>
    <p>Sophia Taglione | DCDA 40833 | Spring 2026</p>

</header>

<main>

<!-- Lab 02 AI tool evaluation -->
<section>
    <h2>Overview</h2>
    <p>
        This lab explores and evaluates AI tools using a structured framework focused on capabilities, appropriate use, ethics, and transparency. Rather than treating AI as a shortcut or productivity hack, this evaluation emphasizes critical thinking and intentional use. By examining how different tools perform, where they fall short, and what ethical concerns they raise, this lab encourages a more thoughtful understanding of AI’s role in academic and creative work. Through hands-on experimentation and reflection, the goal is to develop skills for responsibly assessing AI tools as they continue to evolve and become more integrated into digital culture and data analytics.
    </p>
</section>

<!-- Evaluating ChatGPT -->
<section>
    <h2>Tool Evaluated: ChatGPT</h2>
</section>

<section>
    <h3>Capabilities</h3>
    <p>
        ChatGPT demonstrated strong summarization capabilities when asked to condense an
        academic-style article into five concise bullet points. The output clearly identified
        major themes related to social media use, academic performance, and mental health.
    </p>

    <!-- Evidence from ChatGPT prompts -->
    <figure class="viz-container">
        <img src="images/chatgpt-summary.png" alt="ChatGPT summary output">
        <figcaption>ChatGPT response to article summarization prompt</figcaption>
    </figure>
</section>

<section>
    <h3>Limitations & Appropriate Use</h3>
    <p>
        When prompted to write a 300-word college reflection on digital culture and AI ethics,
        ChatGPT produced a well-structured and fluent response. However, the reflection remained
        fairly general and lacked personal voice and lived experience. This highlights that
        while ChatGPT can assist with brainstorming or outlining, it should not replace original
        student reflection or critical thinking.
    </p>

    <figure class="viz-container">
        <img src="images/chatgpt-reflection.png" alt="ChatGPT reflection output part one">
        <figcaption>ChatGPT generated reflection (part one)</figcaption>
    </figure>

    <figure class="viz-container">
        <img src="images/chatgpt-reflection2.png" alt="ChatGPT reflection output part two">
        <figcaption>ChatGPT generated reflection (part two)</figcaption>
    </figure>
</section>

<section>
    <h3>Transparency & Fact-Checking</h3>
    <p>
        When asked to provide peer-reviewed sources on AI bias, ChatGPT generated a list of
        widely cited academic works. While many sources were legitimate, the response required
        verification to ensure accuracy and proper citation. This reinforces the importance
        of independently fact-checking AI-generated references before using them in academic work.
    </p>

    <figure class="viz-container">
        <img src="images/chatgpt-sources.png" alt="ChatGPT sources output">
        <figcaption>ChatGPT generated list of sources on AI bias</figcaption>
    </figure>
</section>

<section>
    <h3>Ethical Considerations</h3>
    <p>
        Ethical concerns emerged throughout this evaluation, particularly around bias,
        transparency, and authorship. ChatGPT does not disclose its training data in detail,
        making it difficult to fully assess whose perspectives are represented or excluded.
        Additionally, its ability to generate polished academic-style writing raises questions
        about authorship, originality, and appropriate attribution in educational settings.
    </p>
</section>

<section>
    <h3>Reflection & Looking Forward</h3>
    <p>
        This evaluation reinforced the idea that AI tools like ChatGPT are not neutral and must be used thoughtfully. While ChatGPT is effective for brainstorming, outlining, and organizing ideas, this lab showed that it lacks personal perspective and critical nuance when used on its own. Because of this, it works best as a starting point rather than a final product. Moving forward, I see ChatGPT as a supportive tool that can help streamline early stages of academic and professional work, while still requiring human judgment, editing, and ethical responsibility. Developing a structured evaluation framework will help me critically assess how and when to use AI tools as they continue to evolve.
    </p>
</section>

<!-- Evaluating Canva Magic Write -->
<section>
    <h2>Tool Evaluated: Canva Magic Studio</h2>
</section>

<section>
    <h3>Tool Evaluated: Canva Magic Write</h3>
    <p>
        Canva’s Magic Write tool was evaluated to understand its capabilities in generating
        structured written content. When prompted to create an outline on AI ethics, the tool
        produced a clearly organized, presentation-style response that followed a logical flow
        across key ethical themes. However, the outputs remained high-level and generic, offering
        surface-level explanations without citations, concrete examples, or critical depth. While
        Magic Write is useful for brainstorming or organizing ideas, it is not well-suited for
        producing polished academic analysis without significant human revision.
    </p>

    <!-- Canva AI-generated outputs -->
    <figure class="viz-container">
        <img src="images/canva-magicwrite.png" alt="Canva Magic Write AI-generated outline version one">
        <figcaption>Initial Canva Magic Write output outlining key AI ethics topics</figcaption>
    </figure>

    <figure class="viz-container">
        <img src="images/canva-magicwrite2.png" alt="Canva Magic Write AI-generated outline version two">
        <figcaption>Alternate Canva Magic Write output showing a similar structured outline</figcaption>
    </figure>
</section>

<!-- Canva Ethical Considerations -->
<section>
    <h3>Ethical Considerations</h3>
    <p>
        Ethical considerations related to Canva’s Magic Write primarily involve authorship,
        originality, and transparency. Because the tool generates structured written content
        quickly, there is a risk that users may rely on it too heavily without critically
        engaging with the material or adding original thought. Similar to other generative AI
        tools, Magic Write does not clearly disclose how its training data was selected, which
        raises questions about whose perspectives are prioritized in the content it produces.
    </p>
</section>

<!-- Canva Reflection & Looking Forward -->
<section>
    <h3>Reflection & Looking Forward</h3>
    <p>
        Evaluating Canva Magic Write highlighted its usefulness as an organizational and brainstorming tool rather than a source of deep analysis. While it is effective at generating outlines and structured content quickly, the tool consistently produced generalized responses that lacked specificity, nuance, and supporting evidence. This limitation reinforces the importance of human critical thinking when using AI-generated content. Moving forward, I see Magic Write as a helpful starting point for organizing ideas or planning projects, while still requiring human judgment, revision, and ethical responsibility to ensure originality and accuracy.
    </p>
</section>

<!-- Written reflection and analysis based off our AI tools -->
<section>
    <h2>Reflection & Analysis</h2>

    <p>
        This lab explored two AI tools, ChatGPT and Canva Pro’s Magic Write using a structured
        evaluation framework focused on capabilities, appropriate use, ethical considerations,
        and transparency. Testing both tools with prompts related to summarization, reflection
        writing, and structured outlining made it clear that AI can be helpful for efficiency
        and organization, but it also introduces limitations that require human judgment,
        accountability, and critical evaluation.
    </p>

    <p>
        ChatGPT demonstrated strong capabilities in summarizing academic-style content and
        generating coherent, well-structured writing. When prompted to summarize an article
        on the impact of social media on college students, the tool successfully identified
        key themes such as academic distraction, mental health effects, and social connection.
        Its ability to quickly condense information into readable bullet points shows its
        usefulness as a starting point for research or brainstorming. However, when asked
        to produce a reflective essay on digital culture and AI ethics, the responsewhile
        fluent and organized, lacked personal perspective and specificity. This limitation
        highlights that ChatGPT can simulate academic tone but cannot replace lived experience
        or original insight.
    </p>

    <p>
        Canva Pro’s Magic Write offered a different set of strengths and weaknesses. The tool
        excelled at producing clean, presentation-style outlines that followed a logical
        structure. When prompted to generate content on AI ethics, Magic Write organized the
        topic into clear sections such as privacy, bias, transparency, and future considerations.
        This makes it especially useful for early-stage planning or visual projects that require
        structure. At the same time, its outputs remained surface-level and generic, offering
        limited explanation and no supporting evidence. Without significant human revision,
        Magic Write is not well suited for producing in-depth academic analysis.
    </p>

    <p>
        Ethical concerns emerged with both tools, particularly around authorship, bias, and
        transparency. Neither tool fully discloses the datasets used to train their models,
        making it difficult to assess whose perspectives are represented or excluded. ChatGPT’s
        ability to generate convincing academic-style writing raises concerns about originality
        and proper attribution, while Magic Write’s polished outlines may encourage users to
        rely too heavily on templated thinking. Additionally, AI-generated sources and claims
        require independent verification, reinforcing the importance of fact-checking before
        using outputs in academic work.
    </p>

    <p>
        In terms of personal and professional use, these tools are most effective when treated
        as support systems rather than decision-makers. They are valuable for brainstorming,
        outlining, summarizing, and organizing ideas, but they should not replace critical
        thinking, ethical judgment, or original authorship. Within the DCDA program, AI tools
        may enhance learning by increasing efficiency and experimentation, but overreliance
        risks weakening essential skills such as analysis, interpretation, and creative problem
        solving. What remains uniquely human is the ability to contextualize data, make ethical
        decisions, and connect digital tools to cultural meaning.
    </p>

    <p>
        As AI tools continue to evolve, evaluating them requires asking consistent questions:
        What is this tool designed to do? What does it do well or poorly? Where does its
        information come from? Can its outputs be verified? And what responsibilities do users
        have when publishing AI-assisted work? Developing this evaluative mindset is essential
        as AI becomes more embedded in digital culture and data analytics.
    </p>
</section>
</main>

<!-- Footer: Links and copyright -->
    <footer>
        <p><a href="https://github.com/sftaglione/DCDA40833-portfolio">View my Repository on GitHub</a></p>
        <p>&copy; 2026 Sophia Taglione | DCDA 40833 | TCU</p>
    </footer>
</body>
</html>
